So statistics can get a little more controversial than math. And in particular, there are two rival schools of thought or philosophies in statistics, the Bayesians and the frequentists. And Brad Efron, who invented the bootstrap, described this as a 250-year argument that's been raging between the Bayesians in one camp and the frequentists in the other camp. And most first courses in statistics focus on the frequentist approach, which has a lot of strengths but also some weaknesses. And so today, I wanted to talk about the Bayesian approach and how does it compare with the frequentist approach. What is the difference between these two different philosophies of statistics?

And sometimes this gets a little philosophical, debates about which is correct or one method being better than another. But it's not just academic, philosophical wrangling. It actually affects what you do in practice. So it's kind of fun to discuss the philosophical underpinnings, but it also makes a difference in terms of how you analyze your data.

My own philosophical approach tends to be that you should try to be both frequentist and Bayesian, that you can try to get the best of both worlds. So I'll explain what that means. But first, I have to actually tell you, what is the difference being a frequentist approach and a Bayesian approach?

So frequentist is classical statistical method where we have a model. We have some data, and we have some unknown parameters. And for a frequentist, the unknown parameters of the model are regarded as fixed but unknown. So for example, if you have a normal distribution, it has two parameters, the mean and the variance, usually called mu and sigma squared. Those are the two parameters.

We're interested in learning about those parameters. We don't know the true values. But we treat those as constants. There's a mu and a sigma squared. Those are constants that we want to learn about using the data.

So what's random for the frequentist is the data. The data-- we have random variables. And a frequentist-- the reason it's called frequentist is that they're trying to find a method that works well in the long run, if you use this method over and over again. So we're imagining many replications of the experiment. You do the experiment over and over and over again. And sometimes you really do that in real life, and other times it's just hypothetical replications. We're imagining many replications, so we have many datasets. And then we want a method that will work well in the long run, that will have good frequentist performance. It means that if you apply this method many times, you will do well.

Now let me contrast that with the Bayesian approach. The Bayesian wants to focus on the data at hand. Here's our data. And a Bayesian would say, why are you worried about all these hypothetical future datasets that you may never even get? We have a problem, right? We have a data science problem that we want to solve. OK? So give me the best answer for the problem that we have rather than worrying about these hypothetical replications.

So how can a Bayesian do that? Well, the general approach is that the parameters-- so for the normal, it would be the mu and sigma squared-- the parameters are regarded as random variables. It doesn't mean that we're thinking that they're changing randomly. What it means is that we give them a distribution.

So we give some distribution that's called the prior distribution on the parameters, which is just saying, before we look at the data or before we have the data, we're using probability to quantify our uncertainty about those parameters. And then we get some data, and then we update our beliefs or our knowledge about the unknowns that we're interested in.

The reason it's called Bayesian is the way that this update is done. So we're incorporating evidence. We've got some data. That's our evidence. We want to incorporate it to update our beliefs. The way that that's done mathematically is using something called Bayes' rule, which was discovered or invented by Reverend Thomas Bayes. He published it posthumously in 1763, So that's why it's a 250-year argument. But the field has progressed a lot since he was working on that.

OK. So something that often causes confusion about the Bayesian approach is, what's the controversy? So here's Bayes' rule. There was a neon sign of it somewhere. So let me explain this equation.

It says that the probability of a given b is the probability of b given a times the probability of a over the probability of b. So that vertical line is given. It's conditional probability. So p of a given b just means given that we learned that b occurred, what's the probability that a occurred. So if we just have p of a, then we don't know whether b occurred or not, and we're not going to condition on it.

If we have p of a given b, then we know that b occurred, and we want to update our probabilities. OK. So this formula is called Bayes' rule. It was discovered by Bayes, which is why it's named after him. But this is, to me, one of the most surprising theorems in all of mathematics in the sense that the proof of Bayes' rule is just literally one line of algebra. You write down the definition of conditional probability, and Bayes' rule just pops out. I can't think of any other example in all of math where you get as much bang for your buck in the sense that one line of algebra, and you get this theorem that can be applied everywhere.

And the other thing that causes confusion about this a lot is that this is just a theorem. It follows easily from the definition of conditional probability. Why is there a controversy? Bayes' rule is not controversial, so why is Bayesian statistics controversial?

So I wanted to explain the distinction between just using Bayes' rule, which is this theorem, and being a Bayesian statistician. So first, I'll just explain a little bit more about Bayes' rule, and then I'm going to take it into the statistics context. So this is just Bayes' rule as a statement in probability, completely uncontroversial. And then I want to show how do you actually apply that, the statistics and data. OK?

So we're thinking of e as the evidence that we observe and h as some hypothesis that we're interested in. And this is extremely natural in the sense that we want to know what's the probability of our hypothesis being true given the evidence. And a Bayesian would say that they're looking at things in a more natural direction than a frequentist because a frequentist focuses more on the probability of the evidence given that the hypothesis is true.

For example, when you've seen p values in the earlier statistics course, the p value is the probability under the null hypothesis. So given the null hypothesis, what's the probability of getting an observation that's at least as extreme as what was observed? So for a p value, you're conditioning on the null hypothesis being true. And in frequentist methods, you're looking at what happens given a certain parameter value or given a certain hypothesis.

And a Bayesian would say, well, that's not what we're interested in. We're interested in the probabilities for unknowns given what we know. So Bayes' rule itself just is this beautiful relationship between the probability of h given e and the probability of e given h. And one of the most common mistakes in everyday reasoning is confusing the probability of a given b with the probability of b given a.

That's even called the prosecutors' fallacy because there are a lot of examples of prosecutors doing it. And I'm not-- I don't want to get sued. I'm not saying all prosecutors do that. I'm not saying all lawyers do that. It's a common mistake, though, is mixing up a given b and b given a. Those are different quantities, and Bayes' rule shows exactly how they are connected.

So what's controversial here? There's nothing controversial about this as a theorem, but the controversy comes in with how do you use this. So how do I apply this formula? Well, I can't apply this formula unless I specify p of h. So the probability of the hypothesis without being given the data-- that's called the prior.

And most of the controversy with the Bayesian approach come with the choice of the prior with the argument being, well, that that's just your subjective belief about how likely that the hypothesis is, and different people might have different priors, different prior beliefs. And then is that even science if you're just injecting your own subjective opinions? So that's where a lot of the controversies come from there.

And I just wanted to rewrite Bayes' rule one other way that more directly ties it with Bayesian statistics. So suppose that we have data, which I'll write as y, and the parameter, which is usually called data in statistics. This is just exactly Bayes' rule again. But a frequentist-- an anti-Bayesian frequentist would reject even writing this probability of theta given y, because, as I said earlier, they regard theta as fixed. It doesn't have a distribution.

But in the Bayesian approach, we're giving theta a distribution to quantify its uncertainty. And this just says, let's get the probability distribution for our parameter, our unknown of interest given the data. So you'll notice that the p of y in the denominator there-- often, that p of y is very, very difficult to compute. You have to do some horrible sums and integrals if you want to compute that.

But one of the most nice things as a practical matter for taking the Bayesian approach is that for a lot of problems, you don't need to worry about the denominator, the p of y. So if I just write the same equation up to proportionality, we get p of theta given y is proportional to l of theta, the likelihood function, times the prior. So another way to say Bayes' rule is that the posterior distribution-- so posterior means we've conditioned on y-- is proportional to likelihood times prior. The controversy comes with how do you choose that prior.

OK. So to give a little bit more insight into priors and why priors are important, I'll start with a problem that looks really stupid. It looks just like elementary school math. Which proportion is bigger-- 1 out of 2 or 40 out of 100? Well, obviously, 0.5 is bigger than 0.4. So it doesn't seem like a very interesting question. But let me show you how this relates to Bayesian statistics and priors.

OK. So that's just a problem about fractions. Now let's actually give it an applied context. Suppose you're looking at the performance of baseball players. I'm not assuming you know anything about baseball other than that there's a hitter who's trying to hit the ball. OK? And suppose there are two different baseball players, and here's the data that we have about those two different players. So the first player was at bat twice and got one hit, one out of two.

The other player, we have a lot more data. Out of 100 times at bat, Player B got 40 hits-- so the same numbers as in the earlier example, except now I've given it a context. All right. Now, the question is, just based on this data, which baseball player do you think is better?

And that doesn't have one answer. And how you would answer that question depends on how much you know about baseball. So someone who has studied baseball statistics a lot has a lot of information about how well did different players perform and what's considered a good batting average and what's not so good. But even if you know even a little bit about baseball, you know that 40 out of 100, so 40% batting average is extremely good.

Of course, 50% is even better. But notice that the sample sizes are very different here. So 1 out of 2-- that could have easily been 0 out of 2, so 0%. It could have been 2 out of 2, so 100%. But it would be insane based on 2 out of 2 hits to say that you think that that player would have a 100% batting average.

So probably most people who know even a little bit about baseball would think that Player B is probably better. We don't know that for sure, but we're a lot more confident about Player B's batting average. And that seems really good and less likely to be a fluke because there's 100 at-bats there.

So we brought in some prior information. And now one more example, a different context but the same numbers-- let's compare two different cab drivers. Which of these two drivers would you rather have to drive you somewhere if you were taking a cab ride somewhere? Driver A-- here's the data you have. Driver A, 1 time out of 2, reached the desired destination. Driver B, 40 times out of 100, reached the desired destination.

OK. Well, with Driver A, something weird might have happened once. Driver B, that's horrible. That's the worst cab driver ever. 60% of the time, didn't even reach the destination. And that's, again, out of a sample size out of 100. So for the baseball player, my guess would be that Player B is better. But for the cab driver, my guess is that A was better. The exact same numbers.

What we're doing here is that we have some prior information that we're implicitly using. What Bayes' rule does is it lets you explicitly build in your prior information. So whatever prior information you have that might be based on actual data or based on similar types of experiences, explicitly, that can be built into the model, built into your calculations. And you do those updates using Bayes' rule to go from the prior to the posterior.

So we can incorporate our prior information. Bayesian statistics requires us to have a prior. So that's the downside is you have to specify priors on all your unknowns. So it's an additional modeling burden that we have to figure out how to specify our priors, but it's also a major strength that we can incorporate the priors.